{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e09857-57bf-4dcf-9968-fd439fdd8ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f33fa-48d2-4ae7-b9ed-6c3208deda1e",
   "metadata": {},
   "source": [
    "# DICE evaluation metric\n",
    "In the lab semantic segmentation, you have implemented IOU to evaluate the performance of the model. Here, you need to implement a similar evaluation metric called DICE or Sørensen–Dice coefficient, and it is formulated as: $$ DICE(X, X_{truth}) = \\frac{2|X \\cap X_{truth}|}{|X| + |X_{truth}|}$$ \\\n",
    "Compared to IOU, DICE is more sensitive to small differences in overlap due to the squared terms in the numerator and denominator, so it can be more informative when there's a need to discriminate between segmentations with subtle differences in overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba67de8-cad4-4620-afc8-40f897b4d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DICE(inp : Tensor, tgt : Tensor):\n",
    "    \"\"\"\n",
    "    Arguments: \n",
    "        inp: Predicted mask (batchsize, number of classes, width, height)\n",
    "        tgt: Ground truth mask (batchsize, number of classes, width, height)\n",
    "    Returns:\n",
    "        Classwise Average of DICE coefficient\n",
    "    \"\"\"\n",
    "    eps = 1e-5 # small number to add to denominator to avoid division by zero\n",
    "    #YOUR CODE START HERE\n",
    "    sum_dim = (-1, -2, -3)\n",
    "    # calculation of intersection   \n",
    "    inter = 2 *(inp * tgt).sum(dim=sum_dim)\n",
    "\n",
    "    # calculate the sum of |inp| + |tgt|\n",
    "    sets_sum = inp.sum(dim=sum_dim) + tgt.sum(dim=sum_dim)\n",
    "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
    "\n",
    "    # calcaute the dice    \n",
    "    dice = (inter + eps) / (sets_sum + eps)\n",
    "    \n",
    "    # average the dice batchwise\n",
    "    return dice.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e549bf-b9d9-4937-a364-d2252338df8e",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee88cf73-b96f-425b-bda1-c8d693b2ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "prediction1 = Tensor([[0, 7, 5, 7, 2],\n",
    "        [2, 4, 5, 9, 9],\n",
    "        [2, 8, 5, 1, 8],\n",
    "        [3, 6, 5, 2, 6],\n",
    "        [3, 2, 9, 1, 1]]).unsqueeze(0).long()\n",
    "mask1 = Tensor([[4, 2, 5, 0, 2],\n",
    "        [8, 2, 9, 8, 5],\n",
    "        [0, 8, 7, 9, 6],\n",
    "        [8, 6, 5, 9, 1],\n",
    "        [3, 2, 9, 0, 6]]).unsqueeze(0).long()\n",
    "prediction2 = Tensor([[5, 7, 3, 3, 0],\n",
    "        [0, 2, 8, 2, 7],\n",
    "        [1, 7, 0, 9, 9],\n",
    "        [7, 5, 2, 3, 4],\n",
    "        [6, 0, 9, 0, 1]]).unsqueeze(0).long()\n",
    "mask2 = Tensor([[4, 6, 8, 3, 0],\n",
    "        [4, 4, 7, 2, 7],\n",
    "        [0, 0, 4, 9, 9],\n",
    "        [5, 2, 3, 3, 4],\n",
    "        [3, 0, 0, 8, 2]]).unsqueeze(0).long()\n",
    "\n",
    "#Tests\n",
    "dice1 = DICE(F.one_hot(prediction1).permute(0, 3, 1, 2).float(), F.one_hot(mask1).permute(0, 3, 1, 2).float()).item()\n",
    "dice2 = DICE(F.one_hot(prediction2).permute(0, 3, 1, 2).float(), F.one_hot(mask2).permute(0, 3, 1, 2).float()).item()\n",
    "\n",
    "assert np.isclose(0.3200001120567322, dice1), 'incorrect dice 1!'\n",
    "assert np.isclose(0.3600001037120819, dice2), 'incorrect dice 2!'\n",
    "print(\"\\033[92m All tests passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da69bb65-7db7-4b79-8a13-8d1d85a994fe",
   "metadata": {},
   "source": [
    "## Open questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90afc2aa-d450-4057-8fc0-52e2fd400e65",
   "metadata": {},
   "source": [
    "1. Based on their formulation, what are the **difference** among Cross-entropy, DICE, and IOU?  \n",
    "\n",
    "Cross-entropy, DICE, and IOU each measure different aspects of model predictions based on their unique formulations: Cross-entropy loss computes the dissimilarity between the predicted probabilities and the true distribution using a logarithmic function, emphasizing the correct classification by punishing the deviations more heavily for incorrect probabilistic predictions. The DICE coefficient, with its formulation of 2∣X∩Y|/(|X|+|Y|), quantifies the similarity between two sets by considering the relative size of the intersection twice over the combined size of both sets, thereby giving more importance to the commonalities rather than the differences. In contrast, the IOU metric, expressed as |X∩Y|/|X∪Y|,measures the overlap between the predicted and true areas by taking a straightforward ratio of their intersection over their union, without giving additional weight to either the intersection or the size of each set. Thus, while Cross-entropy assesses prediction accuracy on a probabilistic scale, DICE and IOU focus on the spatial overlap, with DICE accentuating the intersection and IOU providing a balanced assessment of the overlap and union.\n",
    "\n",
    "2. How might the choice of architecture, such as U-Net or FFN, affect the performance and application suitability of your semantic segmentation model?\n",
    "\n",
    "The architecture chosen for a semantic segmentation model, like U-Net or a Feedforward Neural Network (FFN), plays a decisive role in the model’s performance and suitability for specific applications. U-Net, designed with convolutional and pooling layers followed by upsampling and concatenation, is adept at capturing detailed spatial contexts and fine-grained features, making it particularly suitable for tasks where precise localization and delineation of objects are critical. Its ability to retain resolution and leverage multi-scale information through skip connections allows for accurate segmentation even with limited training data. In contrast, an FFN, structured in layers that propagate information forward only, may not preserve the spatial relationships as effectively, potentially leading to less accuracy in segment-localization tasks. FFNs could be preferable in scenarios where the segmentation problem is less complex or does not require detailed boundary precision. The selection between these architectures should thus align with the complexity of the segmentation task and the level of detail required in the output.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
